{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eDrcOVDGnyDI",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## About iPython Notebooks ##\n",
    "\n",
    "iPython Notebooks are interactive coding environments embedded in a webpage. You will be using iPython notebooks in this class. Make sure you fill in any place that says `# BEGIN CODE HERE #END CODE HERE`. After writing your code, you can run the cell by either pressing \"SHIFT\"+\"ENTER\" or by clicking on \"Run\" (denoted by a play symbol). Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All). \n",
    "\n",
    " **What you need to remember:**\n",
    "\n",
    "- Run your cells using SHIFT+ENTER (or \"Run cell\")\n",
    "- Write code in the designated areas using Python 3 only\n",
    "- Do not modify the code outside of the designated areas\n",
    "- In some cases you will also need to explain the results. There will also be designated areas for that. \n",
    "\n",
    "Fill in your **NAME** and **AEM** below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "JEJWwHpJnyDK",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "AUTHOR = \"Dimitrios Sourlantzis\"\n",
    "COURSE = \"Machine Learning - CSD AUTH\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QRgauGbInyDM",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "_FF68cfznyDO",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ce63642cafb413e7903d83d2f2cd3637",
     "grade": false,
     "grade_id": "cell-f62db6dce1ed3f2e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Assignment 2 - Decision Trees #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "zq29ctnanyDO",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "29d61ce286fdb8fd61c7f8e89a9e1339",
     "grade": false,
     "grade_id": "cell-dce2e73cee9a5017",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Welcome to your second assignment. This exercise gives you an introduction to [scikit-learn](https://scikit-learn.org/stable/). A simple but efficient machine learning library in Python. It also gives you a wide understanding on how decision trees work. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "mb4Wf4IdnyDP",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "50a108d2f1e1a1ee2fde80743c0543fe",
     "grade": false,
     "grade_id": "cell-83ca2b0456fb85db",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "After this assignment you will:\n",
    "- Be able to use the scikit-learn library and train your own model from scratch.\n",
    "- Be able to train and understand decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "sLqpxgvbnyDQ",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "396c39a0797964c378ebb90cf18a29de",
     "grade": false,
     "grade_id": "cell-2cef6d48eea484d8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Always run this cell\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "\n",
    "# USE THIS RANDOM VARIABLE TO PRODUCE THE SAME RESULTS\n",
    "RANDOM_VARIABLE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eLqRTrLTnyDR",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1. Scikit-Learn and Decision Trees ##\n",
    "\n",
    "You are going to use the scikit-learn library to train a model for detecting breast cancer using the [Breast cancer wisconsin (diagnostic) dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html#sklearn.datasets.load_breast_cancer) (+ [Additional information](https://scikit-learn.org/stable/datasets/toy_dataset.html#breast-cancer-dataset)) by training a model using [decision trees](https://scikit-learn.org/stable/modules/tree.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b7d5K-BdnyDS",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**1.1** Load the breast cancer dataset using the scikit learn library and split the dataset into train and test set using the appropriate function. Use 33% of the dataset as the test set. Define as X the attributes and as y the target values. Do not forget to set the random_state parameter as the *RANDOM_VARIABLE* defined above. Use this variable for all the random_state parameters in this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "id": "NfF54h6anyDS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4b873328ea05f6ef9c08827168c7b835",
     "grade": false,
     "grade_id": "cell-1f0c2f3918333cf6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# BEGIN CODE HERE\n",
    "X, y = load_breast_cancer( return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.33 ,random_state=RANDOM_VARIABLE)\n",
    "\n",
    "#END CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "FiOtzHkpnyDT",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3603b2ba8916ffdad9e9c53f31546b4c",
     "grade": true,
     "grade_id": "cell-3f43c895ceaf57a9",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "9ebabf53-d7c5-4c86-8242-e5826b2ecfc8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Size of train set:381\n",
      "Size of test set:188\n",
      "Unique classes:2\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of train set:{}\".format(len(y_train)))\n",
    "print(\"Size of test set:{}\".format(len(y_test)))\n",
    "print(\"Unique classes:{}\".format(len(set(y_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "JuW_lKVFnyDU",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "62285a7bd3ab59718b89f7e09de0fea4",
     "grade": false,
     "grade_id": "cell-1ce621a108e76a15",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Expected output**:  \n",
    "\n",
    "```\n",
    "Size of train set:381  \n",
    "Size of test set:188  \n",
    "Unique classes:2\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GUB8sl0NnyDV",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**1.2** Train two DecisionTree classifiers and report the F1 score. Use the information gain for the one classifier and the Gini impurity for the other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "id": "nPQFaOhLnyDW",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "17197b62614427a979fcbab7ed2734dd",
     "grade": false,
     "grade_id": "cell-a7fa1d29509eb2a1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# BEGIN CODE HERE\n",
    "classifier_gini = DecisionTreeClassifier(random_state = RANDOM_VARIABLE)\n",
    "classifier_igain = DecisionTreeClassifier(criterion = 'entropy', random_state = RANDOM_VARIABLE)\n",
    "\n",
    "classifier_gini = classifier_gini.fit(X_train, y_train)\n",
    "classifier_igain = classifier_igain.fit(X_train, y_train)\n",
    "\n",
    "prediction_gini = classifier_gini.predict(X_test)\n",
    "prediction_igain = classifier_igain.predict(X_test)\n",
    "\n",
    "f_measure_gini = f1_score(prediction_gini, y_test)\n",
    "f_measure_igain = f1_score(prediction_igain, y_test)\n",
    "\n",
    "#END CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "qToIpGtnnyDX",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6d9aab4355c27c346f7e6548f233e758",
     "grade": true,
     "grade_id": "cell-09657a82bf4028c4",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "fc62bbc0-9ea8-4794-9e1a-670d452f3640",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "F-Measure Gini: 0.9372384937238494\n",
      "F-Measure Information Gain: 0.9596774193548386\n"
     ]
    }
   ],
   "source": [
    "print(\"F-Measure Gini: {}\".format(f_measure_gini))\n",
    "print(\"F-Measure Information Gain: {}\".format(f_measure_igain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "hn9nblQ5nyDY",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f3facbbef0dd8f25ad12bfec7c174818",
     "grade": false,
     "grade_id": "cell-b0d8630f3b764cf3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Expected output**:  \n",
    "\n",
    "```\n",
    "F-Measure Gini: 0.9372384937238494\n",
    "F-Measure Information Gain: 0.9596774193548386\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "31Iyi9SJnyDZ",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f2532168d16e8c9bffba3d7d8e1efce7",
     "grade": false,
     "grade_id": "cell-591ba122016b6db5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**1.3** Find the maximum depth reached by the tree that used the Gini impurity. Train multiple classifiers by modifying the max_depth within the range from 1 to maximum depth and save the f1 scores to the corresponding list of the *fscores* dictionary (one list for training set and one for test set). Before appending the scores to the corresponding list, multiply them by 100, and round the values to 2 decimals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "id": "U7gSfRu_nyDa",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "54cf257e90a3cb5877db81297bedd45c",
     "grade": false,
     "grade_id": "cell-31c58b6161a3907d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# BEGIN CODE HERE\n",
    "depth = classifier_gini.tree_.max_depth\n",
    "fscores = {}\n",
    "fscores['train'] = []\n",
    "fscores['test'] = []\n",
    "\n",
    "for i in range(1,depth+1):\n",
    "    dummy = DecisionTreeClassifier(max_depth = i, random_state = RANDOM_VARIABLE)\n",
    "    dummy = dummy.fit(X_train, y_train)\n",
    "    train_score = dummy.predict(X_train)\n",
    "    test_score = dummy.predict(X_test)\n",
    "    train_score = 100*f1_score(train_score, y_train)\n",
    "    test_score = 100*f1_score(test_score, y_test)\n",
    "    fscores['train'].append(round(train_score, 2))\n",
    "    fscores['test'].append(round(test_score, 2))\n",
    "    \n",
    "#END CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "2395Por-nyDa",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "70a249937f2f690c6ce855debaed204c",
     "grade": true,
     "grade_id": "cell-0c300109423f53b9",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "89563cef-f24d-4096-cab7-c624bf04eb8a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fscores Train: [94.24, 95.46, 97.65, 99.15, 99.37, 99.58, 100.0]\n",
      "Fscores Test:  [91.14, 93.97, 96.64, 94.12, 95.4, 95.04, 93.72]\n"
     ]
    }
   ],
   "source": [
    "print(\"Fscores Train: {}\".format(fscores['train']))\n",
    "print(\"Fscores Test:  {}\".format(fscores['test']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "f37yzYcbnyDb",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3db472d2b9db7a42cc012cd96fdeb499",
     "grade": false,
     "grade_id": "cell-75789627f20d2c94",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Expected output**:  \n",
    "```\n",
    "Fscores Train: [94.24, 95.46, 97.65, 99.15, 99.37, 99.58, 100.0]\n",
    "Fscores Test:  [91.14, 93.97, 96.64, 94.12, 95.4, 95.04, 93.72]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "4stz0V9knyDd",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bca7d4c160c767d27a09b4620d27d56e",
     "grade": false,
     "grade_id": "cell-5906e6d5efa70282",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**1.4** Compare the results from the train set with the results from the test set. What do you notice? How are you going to choose the max_depth of your model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "kwtDaX3JnyDe",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "424ac10e4e22ca9e32207deee3bf0f57",
     "grade": true,
     "grade_id": "cell-c9c6ea0e40d98b83",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# ANSWERS\n",
    "* Fscore Train: F1 score increases as the depth increases\n",
    "\n",
    "* Fscore Test: F1 score increases until a point, reaching maximum, then it starts decreasing.\n",
    "We shall choose a max_depth that guarantees the maximum Test F1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "PIw1fVFenyDe",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "217666fcc2e383d6f2c1904c9d6a71be",
     "grade": false,
     "grade_id": "cell-9ef42e6c90ea2ffe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2.0 Pipelines ##\n",
    "\n",
    "**2.1** In this part of the exercise you are going to build a pipeline from scratch for a classification problem. Load the **income.csv** file and train a DecisionTree model that will predict the *income* variable. This dataset is a modification of the original Adult Income dataset found [here](http://archive.ics.uci.edu/ml/datasets/Adult). Report the f1-score and accuracy score of the test set found in **income_test.csv**. Your pipeline should be able to handle missing values and categorical features (scikit-learn's decision trees do not handle categorical values). You can preprocess the dataset as you like in order to achieve higher scores.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "7jJW-avitO9E",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# BEGIN CODE HERE\n",
    "train_set = pd.read_csv('income.csv')\n",
    "X_train = train_set.drop('income',axis=1)\n",
    "y_train = train_set['income']\n",
    "# any other code you need\n",
    "\n",
    "\n",
    "test_set = pd.read_csv('income_test.csv')\n",
    "X_test = test_set.drop('income',axis=1)\n",
    "y_test = test_set['income']\n",
    "# any other code you need\n",
    "\n",
    "# any other code you need\n",
    "# End CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "akVGpGHDuav4",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**2.2** Create and test your pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "pv6z98huuZ6M",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Your pipeline\n",
    "\n",
    "categorical_features = [X_train.columns[i] for i in range(len(X_train.columns)) \n",
    "          if  X_train.dtypes[i] == 'object']\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"most_frequent\")), \n",
    "           ('encoder', OneHotEncoder())]\n",
    ")\n",
    "\n",
    "numeric_features = [X_train.columns[i] for i in range(len(X_train.columns))\n",
    "                   if X_train.columns[i] not in categorical_features]\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean'))\n",
    "])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"numeric\", numeric_transformer, numeric_features),\n",
    "        (\"categorical\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "#VANILLA CLF WITH EVERYING ON DEFAULT\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"classifier\", DecisionTreeClassifier())])\n",
    "\n",
    "#CLF AFTER HYPERPARAMETER TUNING WITH GRID SEARCH\n",
    "#clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"classifier\", DecisionTreeClassifier(criterion= 'gini', max_depth= 10, max_leaf_nodes= 18, min_samples_leaf= 2, splitter= 'best'))])\n",
    "clf.fit(X_train, y_train)\n",
    "y_predict =  clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "3uaArYmQvKcf",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "79dd5b63-9615-44e6-9700-6c3b4d9765e9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model score Accuracy: 0.808\n",
      "Model score F1 Weighted: 0.809\n"
     ]
    }
   ],
   "source": [
    "print(\"Model score Accuracy: %.3f\" % accuracy_score(y_test, y_predict))\n",
    "print(\"Model score F1 Weighted: %.3f\" % f1_score(y_test, y_predict,average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zz_MWnYY2r3-",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**2.3** Perform a gooood grid search to find the best parameters for your pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "id": "RNECyUFtnyDf",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "152ab2dd6861b198b879a78ebadc4ee4",
     "grade": true,
     "grade_id": "cell-dd950ab2eb40d8a4",
     "locked": false,
     "points": 45,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "fa90c1d0-a85e-4d1c-f6fb-5145f52d943f"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best params:\n",
      "{'classifier__criterion': 'gini', 'classifier__max_depth': 10, 'classifier__max_leaf_nodes': 18, 'classifier__min_samples_leaf': 2, 'classifier__splitter': 'best', 'preprocessor__numeric__imputer__strategy': 'mean'}\n"
     ]
    }
   ],
   "source": [
    "param_grid = [{'classifier__criterion': ['gini', 'entropy'],\n",
    "               'classifier__splitter': ['best', 'random'],\n",
    "               'classifier__max_depth': [5, 10, 15],\n",
    "               'classifier__min_samples_leaf': [2, 5, 8],\n",
    "               'classifier__max_leaf_nodes': [12, 16, 18],\n",
    "               'preprocessor__numeric__imputer__strategy': ['mean', 'median', 'most_frequent']\n",
    "               }]\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "y_predict =  grid_search.predict(X_test)\n",
    "\n",
    "print(\"Best params:\")\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "OhE0haFuw57D",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "e73f684e-2304-4fc1-eae5-412dc963e8c0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model score Accuracy: 0.850\n",
      "Model score F1 Weighted: 0.838\n"
     ]
    }
   ],
   "source": [
    "print(\"Model score Accuracy: %.3f\" % accuracy_score(y_test,y_predict))\n",
    "print(\"Model score F1 Weighted: %.3f\" % f1_score(y_test,y_predict,average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "f_lIQ1-wnyDg",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ee9d4c2635307395bdef2efb941106ae",
     "grade": false,
     "grade_id": "cell-2c3327274958bbad",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**2.4** Describe the process you followed to achieve the results above. Your description should include, but is not limited to the following \n",
    "- How do you handle missing values and why\n",
    "- How do you handle categorical variables and why\n",
    "- Any further preprocessing steps\n",
    "- How do you evaluate your model and how did you choose its parameters \n",
    "- Report any additional results and comments on your approach.\n",
    "\n",
    "You should achieve at least 85% accuracy score and 84% f1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "76FF0gYVnyDh",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1aaf3ddda45b52c2e43089b082d030f1",
     "grade": true,
     "grade_id": "cell-80274fd09b80518c",
     "locked": false,
     "points": 20,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# ANSWERS\n",
    "* When handling missing values, one can choose to ignore the column, ignore the set element or fill in the blank. In this scenario, filling a categorical missing value with the most frequent label value did the trick. For numeric values, we fill the missing value with the mean of the column.\n",
    "* When handling categorical values, OneHotEncoder was used as it allows the representation of categorical data to be more expressive. If we assigned arbitrary label numbers to every categorical value, we could have damaged the perfomance of the model.\n",
    "* Check both numerican and categorical collumns for any missing values and fill them. Then, initialize our transformers with the required steps: \n",
    "  * Numeric Values: Check for missing values and, if found, fill the blanks with the rules proposed previously.\n",
    "  * Categorical Values: Check for missing values and, if found, fill the blanks with the rules proposed previously. Then, encode the value using OneHotEncoder\n",
    "* Predict the output (`y_predict`), compare it with `y_test` and find total matches. We first run the training and evaluation procedures using the default parameters from the Pipeline class, scoring **0.809** on accuracy and **0.810** F1 score. Then we did a thorough grid search to find the optimal hyperparameter values, training our model with these values. (Grid search is very slow on a mere home computer, so it was done using the power of Google Colab Notebooks). Accuracy with tuning: **0.850**, F1 Score with tuning: **0.838**.\n",
    "* The structure of the total pipeline can get very interesting. In this case, two pipelines were created, one for numerical features and one for categorical, each one with their own necessary steps. Those 2 pipelines were then combined to a global pipeline that can train and test the perfomance of the model. This logic can be used for models that have to solve bigger and more complicated problems. While more steps will be required and the model would be more complicated and convoluted, the general idea of combining pipelines can make model building, training and testing easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "mNqPY_yanyDj",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8cef3f333ab449ed91b81ea96695e712",
     "grade": false,
     "grade_id": "cell-555d20216f9bbec2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3.0 Common Issues ## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "USyDSnDCnyDk",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**3.0** Run the following code to define a DecisionTreeModel and load the **income** dataset only with the numerical variables. Then, answer the following questions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "G9M3JhlpnyDl",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ae0f57b86252cc38b02cac3d05e08bbf",
     "grade": false,
     "grade_id": "cell-d7f58621bad12aad",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "56d3485f-9dc3-4843-d10e-863fd4657b5f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model score accuracy: 0.791\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "columns = ['age','fnlwgt','education_num','hours-per-week',\"capital-loss\",\"capital-gain\",\"income\"]\n",
    "data = pd.read_csv('income.csv',usecols=columns)\n",
    "data_test = pd.read_csv('income_test.csv',usecols=columns)\n",
    "\n",
    "# Convert target variable to 0 and 1\n",
    "data[\"income\"] = data[\"income\"].map({ \"<=50K\": 0, \">50K\": 1 })\n",
    "data_test[\"income\"] = data_test[\"income\"].map({ \"<=50K\": 0, \">50K\": 1 })\n",
    "# Create X and y\n",
    "X_train = data.drop([\"income\"],axis=1)\n",
    "y_train = data['income'].values\n",
    "X_test = data_test.drop([\"income\"],axis=1)\n",
    "y_test = data_test['income'].values\n",
    "# Classifier\n",
    "classifier = DecisionTreeClassifier(min_samples_leaf=4)\n",
    "classifier.fit(X_train,y_train)\n",
    "y_predict = classifier.predict(X_test)\n",
    "accuracy_scores = accuracy_score(y_test,y_predict)\n",
    "print(\"Model score accuracy: %.3f\" % accuracy_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Yal5vVVInyDo",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c3981752b539236e99415ab6e2cbea1f",
     "grade": false,
     "grade_id": "cell-9b18d6c4e381a9f5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**3.1** Evaluate the classifier using at least three evaluation metrics except accuracy_score and f1 (weighted)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "id": "4HaPGUuUnyDo",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "12b88026c150b617074a5c06fea36b73",
     "grade": true,
     "grade_id": "cell-905e7dceeb4172c3",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score, average_precision_score, f1_score, brier_score_loss, jaccard_score\n",
    "y_predict = classifier.predict(X_test)\n",
    "\n",
    "# BEGIN CODE HERE\n",
    "metric1 = average_precision_score(y_test,y_predict)\n",
    "metric2 = jaccard_score(y_test,y_predict)\n",
    "metric3 = brier_score_loss(y_test,y_predict)\n",
    "#END CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H03BYlAC6B5u",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1d73b413-b8c8-4ce8-ff0a-93cf694febe4"
   },
   "outputs": [],
   "source": [
    "print(\"Model score Metric 1: %.3f\" % metric1)\n",
    "print(\"Model score Metric 2: %.3f\" % metric2)\n",
    "print(\"Model score Metric 3: %.3f\" % metric3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "YJxhaPxdnyDr",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "361d4753f3c8491a34ff55b6fa3a49b5",
     "grade": false,
     "grade_id": "cell-1f23f3e27600f019",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**3.2** Do you notice any problems with the classifier? If so, what can you do to change this."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ANSWERS\n",
    "\n",
    "What is wrong with the classifier?\n",
    "---\n",
    "  It is obvious that our classifier performs poorly. Let's explain why this is reasonable. Taking a deeper look into our code, we can see that we train our model using raw data: No analysis has been done, we don't have any knowledge of the distribution the data follows, we don't check our data for missing values and we don't encode our data correctly, or at all to be exact. Furthermore, we apply zero balancing to our data prior to fitting. We enforce only the minimum samples per leaf to be 4, an arbitrary value with no real meaning. This leads to the conclusion that no pre-pruning has been applied to the model. All the above leave the model prone to over-fitting or under-fitting.\n",
    "\n",
    "What can we do to increase the performance of the classifier?\n",
    "---\n",
    " - Regarding the data, as mentioned before, we have to do a prior data analysis to our dataset in order to gain more information and discover hidden facts and patterns or the data's distribution. We also can drop columns with missing feature values or fill them with certain methods(mean, frequency etc.). We can distinguish numerical features from the categorical features in dataset. We can encode, then, the categorical features to meaningful values, although in this case we drop all categorical features from the dataset. Last, but not least, we can merge and re-split the data using stratification to balance them.\n",
    " - Regarding the model, we can apply pre-pruning. We can add some hyper-parameters to control the model features like the tree's max depth, the minimum or maximum samples per leaf, the minimum samples required for a leaf to split, and many more. It is very easy for tree models to suffer from overfitting or underfitting, as showed before, so assigning arbitrary values to the above parameters is not recommended at all. We can perform a grid search to tune these hyper-parameters, assign to them an optimal value, and achieve maximum perfomance."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "WCN7E_ctnyDu",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "747645b33cb4f5c14796504fac6bf3ce",
     "grade": false,
     "grade_id": "cell-89715acd6c51b332",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**3.3** Implement your solution using the cells below. Report your results and the process you followed. You are reccommended to use stratification and grid search. You should only have to increase a little bit the metrics you calculated above, and also reach an accuracy score higher than 82%!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "id": "g9Wzx0bknyDv",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ccd1d12620f1a3e1c7b026b862056546",
     "grade": true,
     "grade_id": "cell-f44811f1e99ee41e",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# BEGIN CODE HERE\n",
    "columns = ['age','fnlwgt','education_num','hours-per-week',\"capital-loss\",\"capital-gain\",\"income\"]\n",
    "data = pd.read_csv('income.csv', usecols=columns) #LOAD TRAIN DATASET\n",
    "data_test = pd.read_csv('income_test.csv', usecols=columns) #LOAD TEST DATASET\n",
    "data[\"income\"] = data[\"income\"].map({ \"<=50K\": 0, \">50K\": 1 }) #ENCODE INCOME - TRAIN DATASET\n",
    "data_test[\"income\"] = data_test[\"income\"].map({ \"<=50K\": 0, \">50K\": 1 }) #ENCODE INCOME - TEST DATASET\n",
    "# data_all = pd.concat([data, data_test], ignore_index=True) #MERGE DATASETS\n",
    "\n",
    "#CONFIGURE INPUT-OUTPUT\n",
    "y = data['income']\n",
    "X = data.drop('income',axis=1)\n",
    "\n",
    "#SPLIT AGAIN USING STRATIFICATION\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=RANDOM_VARIABLE, stratify=y)\n",
    "\n",
    "print()\n",
    "#BUILD USUAL PIPELINE AND EVALUATED CONFIGURED MODEL\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"numeric\", numeric_transformer, X_train.columns)\n",
    "    ]\n",
    ")\n",
    "\n",
    "new_clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"classifier\", DecisionTreeClassifier())])\n",
    "\n",
    "param_grid = [{'classifier__criterion': ['gini', 'entropy'],\n",
    "               'classifier__splitter': ['best', 'random'],\n",
    "               'classifier__max_depth': [5, 10, 15],\n",
    "               'classifier__min_samples_leaf': [2, 5, 8],\n",
    "               'classifier__max_leaf_nodes': [12, 16, 18],\n",
    "               'preprocessor__numeric__imputer__strategy': ['mean', 'median', 'most_frequent']\n",
    "               }]\n",
    "\n",
    "grid_search = GridSearchCV(new_clf, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "y_predict =  grid_search.predict(X_test)\n",
    "\n",
    "metric1 = average_precision_score(y_test,y_predict)\n",
    "metric2 = jaccard_score(y_test,y_predict)\n",
    "metric3 = brier_score_loss(y_test,y_predict)\n",
    "\n",
    "final_score = \"\"\n",
    "\n",
    "# #END CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HoDBPL6n6LLI",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "eb4da79e-1cac-47e7-f482-adc97b0cb8e1"
   },
   "outputs": [],
   "source": [
    "print(\"Model score Accuracy: %.3f\" % accuracy_score(y_test,y_predict))\n",
    "print(\"Model score F1 Weighted: %.3f\" % f1_score(y_test,y_predict,average='weighted'))\n",
    "print(\"Model score Metric 1: %.3f\" % metric1)\n",
    "print(\"Model score Metric 2: %.3f\" % metric2)\n",
    "print(\"Model score Metric 3: %.3f\" % metric3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "ZyG7hhbFnyDx",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b26041c1723d2858ad0833f8985801db",
     "grade": true,
     "grade_id": "cell-c99ca88f33f3717c",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Results:\n",
    "---\n",
    "We can see that model accuracy went up to 83.3% and F1 Weighted score is 81.6%, an adequate result as it is above 82%. Metric 1 (Average Precision) went from 0.414 up to 0.473, Metric 2(Jaccard Score - Similarity Score) went from 0.363 up to 0.390 and, finally, metric 3(Brier Score Loss - Mean Squared Error) dropped from 0.209 to 0.167.\n",
    "\n",
    "What did we do differently?\n",
    "---\n",
    "First of all, we merged the datasets and splitted them back differently, using stratification, so the dataset is well-balanced. We checked the train dataset for missing values and filled them, we distinguish the numerical features from the categorical features in the dataset. We left the categorical values out of the dataset as asked, although we could have encoded the categorical features to meaningful values, using OneHotEncoder. Last but not least, we performed a grid search to tune every chosen hyperparameter. Combining all the above, we secured the good perfomance of the classifier."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "9868_Dimitrios_Sourlantzis_sourland_ece_auth_gr_DecisionTrees.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}